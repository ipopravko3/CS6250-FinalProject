{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119dd09a",
   "metadata": {},
   "source": [
    "This script aims to reproduce the synthetic ePBRN-error-simulated datasets for Scheme B, which are stored in two files ePBRN_D_dup.csv and ePBRN_F_dup.csv. The original datasets used dont have any duplicated in them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea877fb0",
   "metadata": {},
   "source": [
    "#### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9dc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import choice\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bad0e6",
   "metadata": {},
   "source": [
    "#### Initializing weights and percentage of shared records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f1595",
   "metadata": {},
   "source": [
    "The following weighs and percentages are replicated as is from the paper so that the data reproduced matches with the data used in this paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b130d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the percentage of  [2, 3, 4] shared records in one linkage:\n",
    "count_shared = [1.68+21.0659, 1.9986 + 0.0471, 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed8199",
   "metadata": {},
   "source": [
    "#### Defining functions to process the original data and reproduce simulated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a8c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and pre-processing the input data\n",
    "def preprocess(inputfile):\n",
    "    df = pd.read_csv(\n",
    "        PATH_DATA+inputfile+\".csv\", \n",
    "        parse_dates=[\"date_of_birth\"])\n",
    "    df['street_number'] = df['street_number'].fillna('0').astype(int)\n",
    "    df['postcode'] =   df['postcode'].fillna('0000').astype(int)\n",
    "    df['day'] = df['date_of_birth'].dt.strftime('%d')\n",
    "    df['month'] = df['date_of_birth'].dt.strftime('%m')\n",
    "    df['year'] = df['date_of_birth'].dt.strftime('%Y')\n",
    "    df[\"rec_id\"] = range(len(df))\n",
    "    df['rec_id'] = df['rec_id'].astype(str)\n",
    "    df.fillna({'surname':'',\\\n",
    "               'given_name':'',\\\n",
    "               'given_name':'',\\\n",
    "               'address_1':'',\\\n",
    "               'address_2':'',\\\n",
    "               'day':'',\\\n",
    "               'month':'',\\\n",
    "               'year':''}, inplace=True)\n",
    "    df[\"match_id\"] = range(len(df))\n",
    "    \n",
    "    df = df.drop([\"age\", \"phone_number\", \"soc_sec_id\", \"blocking_number\", \"date_of_birth\"], axis=1)\n",
    "    col_list = df.columns.values.tolist()\n",
    "    col_list.remove('rec_id')\n",
    "    \n",
    "    print(\"============================================================================================\")\n",
    "    print(\"Data preprocess success\")\n",
    "    print(\"============================================================================================\")\n",
    "    print(\"[1] Total records in \", inputfile, \" :\", len(df))\n",
    "    print(\"[2] Preprocessed \", inputfile, \" data sample :\")\n",
    "    print(df.head())\n",
    "    print(\"============================================================================================\")\n",
    "    \n",
    "    return df, col_list\n",
    "\n",
    "#Sampling and generating random indices for the reproduced linkages.\n",
    "def sampling(df, count_shared):\n",
    "    records = len(df)\n",
    "    double = int(records*count_shared[0]/100)\n",
    "    triple = int(records*count_shared[1]/100)\n",
    "    quad = int(records*count_shared[2]/100)\n",
    "    \n",
    "    list_double_linked = random.sample(range(records),k=double)\n",
    "    unlinked = [item for item in range(records) if item not in list_double_linked]\n",
    "    list_triple_linked = random.sample(unlinked,k=triple)\n",
    "    unlinked = [item for item in unlinked if item not in list_triple_linked]\n",
    "    list_quad_linked = random.sample(unlinked,k=quad)\n",
    "    \n",
    "    tot_rec_gen = records + double + triple*2 + quad*3\n",
    "    matched = double + triple*3 + quad*6\n",
    "    print(\"============================================================================================\")\n",
    "    print(\"Sampling and random indices generation success\")\n",
    "    print(\"============================================================================================\")\n",
    "    print(\"[1] Total records in \", inputfile, \" :\", records)\n",
    "    print(\"[2] Double links:\", double)\n",
    "    print(\"[3] Triple links:\",triple)\n",
    "    print(\"[4] Quad links:\",quad)\n",
    "    print(\"[5] Total records after generated:\", tot_rec_gen)\n",
    "    print(\"[6] Matched pairs:\", matched)\n",
    "    print(\"============================================================================================\")\n",
    "    \n",
    "    return list_double_linked, list_triple_linked, list_quad_linked\n",
    "    \n",
    "# Process each record \n",
    "def process_record(rc, all_fields):\n",
    "    # Assigning the weights for each type of error:\n",
    "    #The following weighs and percentages are replicated as is from the paper so\n",
    "    # that the data reproduced matches with the data used in this paper.\n",
    "    abr = 1 # abbreviation on surname: Michael -> M\n",
    "    jwd1 = 1 # join with dash: John Peter -> John-Peter, join surname and given name into surname\n",
    "    jwd2 = 1 # join with dash: John Peter -> John-Peter, join surname and given name into given name\n",
    "    jwb1 = 1 # join with blank: \n",
    "    jwb2 = 1 # join with blank: \n",
    "    drf = 1 # drop all tokens in any field\n",
    "    dlc1 = 1 # drop last character in surname: Peter -> Pete\n",
    "    dlc2 = 1 # drop last character in given name\n",
    "    swn = 1 # swap surname and given name: John Peter -> Peter John\n",
    "    swc1 = 1 # swap character in surname: Peter -> Petre\n",
    "    swc2 = 1 # swap character in given name: Peter -> Petre\n",
    "    swd = 1 # swap day and month fields: 12/04 -> 04/12\n",
    "    rsd = 1 # reset day and month: 12/04/1991 -> 01/01/1991\n",
    "    chy = 1 # change year of birth by a margin of (+/-)5 \n",
    "    drz1 = 1 # drop leading zeros from day of birth: 02/04 -> 2/04\n",
    "    drz2 = 1 # drop leading zeros from month of birth: 02/04 -> 02/4\n",
    "    chz = 1 # change any number of digit from zip code\n",
    "    mar = 1 # change the whole token of surname: Mary Ward -> Mary Winston\n",
    "    twi = 1 # duplicate all fields except given name: Micheal Williams -> Leo Williams\n",
    "    add = 1 # change the whole 3 fields of address by randomly replacing each field by any other row\n",
    "\n",
    "    all_error_types = ['abr','jwd1','jwd2','jwb1','jwb2' ,'drf','dlc1','dlc2','swn',\n",
    "                       'rsd','chy','chz','mar','twi','add']\n",
    "    all_error_weights = [abr, jwd1, jwd2, jwb1, jwb2, drf, dlc1, dlc2, swn, rsd, chy, chz, mar, twi, add]\n",
    "    all_error_weights = all_error_weights/sum(np.asarray(all_error_weights))\n",
    "    \n",
    "    no_error = np.random.poisson(1, 1)\n",
    "    errortypes = choice(all_error_types, no_error, p=all_error_weights)\n",
    "    for errortype in errortypes:\n",
    "        if errortype == 'abr':\n",
    "            if len(rc[\"surname\"])>0:\n",
    "                #rc[\"surname\"] = rc[\"surname\"][0]\n",
    "                rc.at[\"surname\"] = rc[\"surname\"][0]\n",
    "        if errortype == 'jwd1':\n",
    "            rc.at[\"surname\"] = rc[\"surname\"]+'-' +rc[\"given_name\"]\n",
    "            rc.at[\"given_name\"] = ''\n",
    "        if errortype == 'jwd2':\n",
    "            rc.at[\"given_name\"] = rc[\"surname\"]+'-' +rc[\"given_name\"]\n",
    "            rc.at[\"surname\"] = ''\n",
    "        if errortype == 'jwb1':\n",
    "            rc.at[\"surname\"] = rc[\"surname\"]+' ' +rc[\"given_name\"]\n",
    "            rc.at[\"given_name\"] = ''\n",
    "        if errortype == 'jwb2':\n",
    "            rc.at[\"given_name\"] = rc[\"surname\"]+' ' +rc[\"given_name\"]\n",
    "            rc.at[\"surname\"] = ''\n",
    "        if errortype == 'drf':    \n",
    "            selected_field = random.choice(all_fields)\n",
    "            rc.at[selected_field] = ''\n",
    "        if errortype == 'dlc1':\n",
    "            if len(rc[\"surname\"])>0:\n",
    "                rc.at[\"surname\"] = rc['surname'][0:-1]\n",
    "        if errortype == 'dlc2':\n",
    "            if len(rc[\"given_name\"])>0:\n",
    "                rc.at[\"given_name\"] = rc['given_name'][0:-1]\n",
    "        if errortype == 'swn':\n",
    "            temp = rc['given_name']\n",
    "            rc.at[\"given_name\"] = rc['surname']\n",
    "            rc.at[\"surname\"] = temp\n",
    "        if errortype == 'swd': \n",
    "            temp = rc['day']\n",
    "            rc.at['day'] = rc['month']\n",
    "            rc.at['month'] = temp\n",
    "        if errortype == 'rsd':\n",
    "            rc.at['day'] = '01'\n",
    "            rc.at['month'] = '01'\n",
    "        if errortype == 'chy': \n",
    "            if rc.at['year'] != 'NaT' and rc['year'] != '':\n",
    "                margin = random.choice(range(-5,5))\n",
    "                rc.at['year'] = str( int(rc['year']) + margin)\n",
    "        if errortype == 'chz':\n",
    "            if len(str(rc['postcode']))== 4:\n",
    "                selected_digit = random.choice(range(4))\n",
    "                code = list(str(rc['postcode']))\n",
    "                code[selected_digit] = str( random.choice(range(9)))\n",
    "                rc.at['postcode'] = int(''.join(code))\n",
    "        if errortype == 'mar':\n",
    "            rc.at[\"surname\"] = df.iloc[random.choice(range(len(df)))]['surname']\n",
    "        if errortype == 'twi':\n",
    "            rc.at[\"given_name\"] = df.iloc[random.choice(range(len(df)))]['given_name']\n",
    "        if errortype == 'add':\n",
    "            rc.at['address_1'] = df.iloc[random.choice(range(len(df)))]['address_1']\n",
    "            rc.at['address_2'] = df.iloc[random.choice(range(len(df)))]['address_2']\n",
    "            rc.at['street_number'] = random.choice(range(500))\n",
    "    return rc\n",
    "\n",
    "def data_synthesizer(df, list_double_linked, list_triple_linked, list_quad_linked, outputfile):\n",
    "    counter = 0\n",
    "    processed_df = df\n",
    "    for linked_list in [list_double_linked, list_triple_linked, list_quad_linked]:\n",
    "        counter += 1\n",
    "        for each in linked_list:\n",
    "            for k in range(counter):\n",
    "                each_record = df.iloc[each]\n",
    "                processed_record = process_record(each_record, all_fields)\n",
    "                processed_record.at[\"rec_id\"] = processed_record[\"rec_id\"] + \"-dup-\" + str(k)\n",
    "                processed_df = processed_df.append(processed_record)\n",
    "    \n",
    "    OP_path = PATH_DATA + outputfile + \".csv\" \n",
    "    processed_df.to_csv(OP_path, index=False)\n",
    "    print(\"============================================================================================\")\n",
    "    print(\"Data reproduction success\")\n",
    "    print(\"============================================================================================\")\n",
    "    print(\"[1] Total records in \", outputfile, \" :\", len(processed_df))\n",
    "    print(\"[2] Reproduced data sample :\")\n",
    "    print(processed_df.head())\n",
    "    print(\"[3] Data saved path :\",OP_path)\n",
    "    print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc8340",
   "metadata": {},
   "source": [
    "#### Recreation of F and D ePBRN datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c6380",
   "metadata": {},
   "source": [
    "##### F dataset recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b792d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Data preprocess success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_F_original  : 11100\n",
      "[2] Preprocessed  ePBRN_F_original  data sample :\n",
      "  rec_id given_name   surname  street_number         address_1 address_2  \\\n",
      "0      0      jenna    kilpin            179    mcfarlan place             \n",
      "1      1     bianca  randazzo             37  lindrum crescent  sunshine   \n",
      "2      2      james   borlase             75                     rocklea   \n",
      "3      3   nicholas    beeton             20         mugga way             \n",
      "4      4      megan   footner              4      jewell close             \n",
      "\n",
      "          suburb  postcode state day month  year  match_id  \n",
      "0       hillarys      2768   vic  26    02  1950         0  \n",
      "1        forster      2281    wa  07    04  1988         1  \n",
      "2         casula      2460   qld  03    09  1913         2  \n",
      "3       hawthorn      2480   vic  22    06  1999         3  \n",
      "4  taylors lakes      3129   tas  22    09  1912         4  \n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Sampling and random indices generation success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_F_original  : 11100\n",
      "[2] Double links: 2524\n",
      "[3] Triple links: 227\n",
      "[4] Quad links: 5\n",
      "[5] Total records after generated: 14093\n",
      "[6] Matched pairs: 3235\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Data reproduction success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_F_dup  : 14093\n",
      "[2] Reproduced data sample :\n",
      "  rec_id given_name   surname street_number         address_1 address_2  \\\n",
      "0      0      jenna    kilpin           179    mcfarlan place             \n",
      "1      1     bianca  randazzo            37  lindrum crescent  sunshine   \n",
      "2      2      james   borlase            75                     rocklea   \n",
      "3      3   nicholas    beeton            20         mugga way             \n",
      "4      4      megan   footner             4      jewell close             \n",
      "\n",
      "          suburb postcode state day month  year match_id  \n",
      "0       hillarys     2768   vic  26    02  1950        0  \n",
      "1        forster     2281    wa  07    04  1988        1  \n",
      "2         casula     2460   qld  03    09  1913        2  \n",
      "3       hawthorn     2480   vic  22    06  1999        3  \n",
      "4  taylors lakes     3129   tas  22    09  1912        4  \n",
      "[3] Data saved path : ../data/ePBRN_F_dup.csv\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = \"../data/\"\n",
    "inputfile = 'ePBRN_F_original' \n",
    "outputfile = 'ePBRN_F_dup' \n",
    "\n",
    "df, all_fields = preprocess(inputfile)\n",
    "list_double_linked, list_triple_linked, list_quad_linked = sampling(df, count_shared)\n",
    "data_synthesizer(df, list_double_linked, list_triple_linked, list_quad_linked, outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc297e3",
   "metadata": {},
   "source": [
    "##### D dataset recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b1d085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Data preprocess success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_D_original  : 9250\n",
      "[2] Preprocessed  ePBRN_D_original  data sample :\n",
      "  rec_id given_name        surname  street_number         address_1  \\\n",
      "0      0      riley         cowley              2   ballarat street   \n",
      "1      1   maddison          hiley              5  limestone avenue   \n",
      "2      2     thomas        roberts             49   fortescue place   \n",
      "3      3     nasyah  van der ploeg            395    kenyon circuit   \n",
      "4      4       zara          denne             19                     \n",
      "\n",
      "          address_2     suburb  postcode state day month  year  match_id  \n",
      "0                       laguna      4218   vic                         0  \n",
      "1        lochenfels     cobram      6415   nsw  14    04  1921         1  \n",
      "2  dp 12750 talunga  leongatha      2911   qld  16    01  1907         2  \n",
      "3                     oakleigh      2515   NaN                         3  \n",
      "4         bestblock  kingsford      5290    sa  11    11  1911         4  \n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Sampling and random indices generation success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_D_original  : 9250\n",
      "[2] Double links: 2103\n",
      "[3] Triple links: 189\n",
      "[4] Quad links: 4\n",
      "[5] Total records after generated: 11743\n",
      "[6] Matched pairs: 2694\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Data reproduction success\n",
      "============================================================================================\n",
      "[1] Total records in  ePBRN_D_dup  : 11743\n",
      "[2] Reproduced data sample :\n",
      "  rec_id given_name        surname street_number         address_1  \\\n",
      "0      0      riley         cowley             2   ballarat street   \n",
      "1      1   maddison          hiley             5  limestone avenue   \n",
      "2      2     thomas        roberts            49   fortescue place   \n",
      "3      3     nasyah  van der ploeg           395    kenyon circuit   \n",
      "4      4       zara          denne            19                     \n",
      "\n",
      "          address_2     suburb postcode state day month  year match_id  \n",
      "0                       laguna     4218   vic                        0  \n",
      "1        lochenfels     cobram     6415   nsw  14    04  1921        1  \n",
      "2  dp 12750 talunga  leongatha     2911   qld  16    01  1907        2  \n",
      "3                     oakleigh     2515   NaN                        3  \n",
      "4         bestblock  kingsford     5290    sa  11    11  1911        4  \n",
      "[3] Data saved path : ../data/ePBRN_D_dup.csv\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = \"../data/\"\n",
    "inputfile = 'ePBRN_D_original' \n",
    "outputfile = 'ePBRN_D_dup' \n",
    "\n",
    "df, all_fields = preprocess(inputfile)\n",
    "list_double_linked, list_triple_linked, list_quad_linked = sampling(df, count_shared)\n",
    "data_synthesizer(df, list_double_linked, list_triple_linked, list_quad_linked, outputfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
